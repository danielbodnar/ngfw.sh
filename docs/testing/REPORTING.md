# Test Reporting and Dashboards

Comprehensive guide to test reporting, monitoring, and visualization for NGFW.sh.

---

## Table of Contents

1. [Test Reports Overview](#test-reports-overview)
2. [CI/CD Test Reports](#cicd-test-reports)
3. [Coverage Dashboards](#coverage-dashboards)
4. [Test Result Analysis](#test-result-analysis)
5. [Quality Gates](#quality-gates)
6. [Alerting and Notifications](#alerting-and-notifications)

---

## Test Reports Overview

### Report Types

| Report Type | Frequency | Format | Audience |
|-------------|-----------|--------|----------|
| **CI/CD Test Results** | Every commit/PR | GitHub Actions | Developers |
| **Coverage Reports** | Every commit/PR | HTML, JSON, LCOV | Developers, QA |
| **Weekly Test Summary** | Weekly | Markdown, Email | Engineering team |
| **Monthly Quality Report** | Monthly | PDF, Slides | Leadership |
| **Security Audit** | Weekly | HTML, JSON | Security team |

### Report Storage

```
reports/
â”œâ”€â”€ ci/                    # CI/CD test results
â”‚   â”œâ”€â”€ 2026-02-09/
â”‚   â”‚   â”œâ”€â”€ test-schema.xml
â”‚   â”‚   â”œâ”€â”€ test-rust.xml
â”‚   â”‚   â””â”€â”€ integration.xml
â”‚   â””â”€â”€ latest/           # Symlink to most recent
â”œâ”€â”€ coverage/             # Coverage reports
â”‚   â”œâ”€â”€ schema/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ lcov.info
â”‚   â”‚   â””â”€â”€ coverage.json
â”‚   â”œâ”€â”€ rust/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ cobertura.xml
â”‚   â””â”€â”€ aggregated/       # Combined coverage
â”œâ”€â”€ security/             # Security audit reports
â”‚   â”œâ”€â”€ dependency-check/
â”‚   â””â”€â”€ owasp/
â””â”€â”€ summaries/            # Weekly/monthly summaries
    â”œâ”€â”€ weekly/
    â””â”€â”€ monthly/
```

---

## CI/CD Test Reports

### GitHub Actions Test Report

**Location:** GitHub Actions â†’ Workflow â†’ Test job

**Contents:**
- Test execution time per package
- Pass/fail status
- Failed test details
- Coverage metrics
- Build artifacts

**Example Output:**

```
âœ“ Lint (2m 34s)
âœ“ Test Rust API (4m 12s)
  â”œâ”€ Unit tests: 120 passed
  â”œâ”€ Integration tests: 8 passed
  â””â”€ Coverage: 75.3% (+2.1%)
âš  Test Schema API (1m 45s)
  â””â”€ Blocked: vitest v4 incompatibility
âœ“ Integration Tests (Docker) (3m 28s)
  â”œâ”€ Agent startup: PASS
  â”œâ”€ WebSocket connection: PASS
  â””â”€ Metrics reporting: PASS
âœ“ Build Verification (5m 16s)
âœ“ Security Audit (2m 08s)
  â””â”€ 0 vulnerabilities found
```

### JUnit XML Reports

**Generated by:** Vitest, cargo test

**Format:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<testsuites name="ngfw.sh" tests="145" failures="0" errors="0" time="23.45">
  <testsuite name="packages/api" tests="120" failures="0" errors="0" time="18.32">
    <testcase name="test_auth_message_serialization" time="0.012"/>
    <testcase name="test_status_payload_validation" time="0.018"/>
    <!-- ... more tests ... -->
  </testsuite>
  <testsuite name="packages/schema" tests="25" failures="0" errors="0" time="5.13">
    <testcase name="should create task" time="0.142"/>
    <testcase name="should validate input" time="0.089"/>
    <!-- ... more tests ... -->
  </testsuite>
</testsuites>
```

**Usage:**

```bash
# Vitest
bun run test --reporter=junit --outputFile=reports/ci/test-schema.xml

# Rust
cargo test -- --format=junit > reports/ci/test-rust.xml
```

### Test Result Artifacts

**Uploaded to GitHub:**

- JUnit XML reports
- Coverage reports (HTML + LCOV)
- Integration test logs
- OWASP dependency check reports
- Failed test screenshots (E2E)

**Retention:** 90 days

**Access:**

```bash
# Download artifacts from workflow
gh run download <run-id> --name test-results

# View in browser
gh run view <run-id> --web
```

---

## Coverage Dashboards

### Codecov Dashboard

**URL:** https://codecov.io/gh/danielbodnar/ngfw.sh

**Features:**
- Real-time coverage tracking
- Coverage trends over time
- File-level coverage heatmap
- PR coverage comparison
- Sunburst visualization

**Integration:**

```yaml
# .github/workflows/test.yml
- name: Upload coverage to Codecov
  uses: codecov/codecov-action@v4
  with:
    token: ${{ secrets.CODECOV_TOKEN }}
    files: ./packages/schema/coverage/lcov.info,./packages/api/coverage/cobertura.xml
    flags: schema-api,rust-api
    name: ngfw-coverage
```

**Viewing Coverage:**

1. **Overall:** https://codecov.io/gh/danielbodnar/ngfw.sh
2. **By Package:**
   - Schema API: `?flag=schema-api`
   - Rust API: `?flag=rust-api`
3. **By Branch:** Select branch from dropdown
4. **By PR:** Automatically commented on PRs

### Local Coverage Dashboard

**Generate HTML reports:**

```bash
# Schema API
cd packages/schema
bun run test --coverage
open coverage/index.html

# Rust API
cd packages/api
cargo tarpaulin --out Html
open coverage/index.html
```

**Coverage Report Structure:**

```
coverage/
â”œâ”€â”€ index.html              # Main dashboard
â”œâ”€â”€ base.css                # Styling
â”œâ”€â”€ prettify.css
â”œâ”€â”€ prettify.js
â”œâ”€â”€ sorter.js
â””â”€â”€ src/
    â”œâ”€â”€ index.html          # Package-level coverage
    â”œâ”€â”€ endpoints/
    â”‚   â”œâ”€â”€ fleet/
    â”‚   â”‚   â”œâ”€â”€ index.html  # Module coverage
    â”‚   â”‚   â””â”€â”€ create.ts.html  # File coverage
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
```

**Coverage Color Coding:**

- ğŸŸ¢ Green (80-100%): Good coverage
- ğŸŸ¡ Yellow (50-79%): Moderate coverage
- ğŸ”´ Red (0-49%): Poor coverage

### Custom Coverage Dashboard

**Stack:** Grafana + InfluxDB

**Metrics Tracked:**

- Coverage percentage (line, branch, function)
- Coverage trends (daily, weekly, monthly)
- Package-level coverage breakdown
- Critical path coverage status
- Test count and execution time

**Grafana Panels:**

1. **Coverage Trend** (Line chart)
   - X: Date
   - Y: Coverage %
   - Series: schema-api, rust-api, portal

2. **Package Coverage** (Bar chart)
   - X: Package
   - Y: Coverage %
   - Target line: 80%

3. **Critical Paths** (Table)
   - Path | Coverage | Status
   - Auth | 60% | âš ï¸
   - Device Mgmt | 85% | âœ…

4. **Test Execution Time** (Histogram)
   - X: Test duration
   - Y: Test count

**Dashboard Configuration:**

```json
{
  "dashboard": {
    "title": "NGFW.sh Test Coverage",
    "panels": [
      {
        "title": "Coverage Trend",
        "type": "graph",
        "datasource": "InfluxDB",
        "targets": [
          {
            "measurement": "coverage",
            "select": [["field", "line_coverage"]],
            "groupBy": [{"type": "time", "params": ["1d"]}]
          }
        ]
      }
    ]
  }
}
```

---

## Test Result Analysis

### Test Pass/Fail Trends

**Tracking:**

```
Jan 2026:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 95%
Feb 2026:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
```

**Metrics:**

| Metric | Jan 2026 | Feb 2026 | Change |
|--------|----------|----------|--------|
| Total Tests | 132 | 145 | +13 |
| Passing | 125 | 145 | +20 |
| Failing | 7 | 0 | -7 |
| Flaky | 3 | 0 | -3 |
| Pass Rate | 94.7% | 100% | +5.3% |

### Test Execution Time Analysis

**Average Test Time:**

| Test Type | Time | Target | Status |
|-----------|------|--------|--------|
| Unit (TypeScript) | 0.8s | < 1s | âœ… |
| Unit (Rust) | 0.5s | < 1s | âœ… |
| Integration (Docker) | 28s | < 30s | âœ… |
| Integration (QEMU) | 115s | < 120s | âœ… |

**Slowest Tests:**

| Test | Time | Package | Optimization |
|------|------|---------|--------------|
| Device CRUD full cycle | 3.2s | schema | Consider parallel |
| QEMU VM boot | 45s | integration | âš ï¸ Necessary |
| Coverage generation | 18s | rust | Use cache |

### Flaky Test Detection

**Definition:** Test that fails intermittently without code changes

**Current Flaky Tests:** 0 âœ…

**Historical Flaky Tests:**

| Test | Flake Rate | Root Cause | Fix |
|------|------------|------------|-----|
| WebSocket connection | 15% | Race condition | Added wait logic |
| Database migration | 8% | Timing issue | Fixed in setup |
| API token refresh | 5% | Clock skew | Mocked time |

**Flaky Test Dashboard:**

```bash
# Run tests 100 times to detect flakiness
for i in {1..100}; do
  bun run test --reporter=json > results-$i.json
done

# Analyze results
node scripts/analyze-flakiness.js results-*.json
```

---

## Quality Gates

### CI/CD Quality Gates

**Pull Request Checks:**

| Check | Requirement | Block Merge |
|-------|-------------|-------------|
| Lint | 0 errors | âœ… Yes |
| Unit Tests | 100% pass | âœ… Yes |
| Integration Tests | 100% pass | âœ… Yes |
| Coverage (overall) | â‰¥ 75% | âš ï¸ Warning |
| Coverage (new code) | â‰¥ 80% | âœ… Yes |
| Critical path coverage | 100% | âœ… Yes |
| Security audit | 0 high/critical | âœ… Yes |

**Branch Protection Rules:**

```yaml
# .github/branch-protection.yml
main:
  required_status_checks:
    strict: true
    contexts:
      - "Lint"
      - "Test Rust API"
      - "Test Schema API"
      - "Integration Tests (Docker)"
      - "Build Verification"
      - "Security Audit"
  required_approving_reviews: 2
  required_linear_history: true
```

### Pre-Merge Checklist

**Automated:**

- [x] All tests pass
- [x] Code coverage meets threshold
- [x] No linting errors
- [x] No security vulnerabilities
- [x] Build succeeds

**Manual:**

- [ ] Code review completed
- [ ] Documentation updated
- [ ] CHANGELOG.md updated
- [ ] Migration guide (if breaking change)

---

## Alerting and Notifications

### Slack Notifications

**Trigger Events:**

| Event | Channel | Severity |
|-------|---------|----------|
| Test failure on main | #engineering | ğŸ”´ High |
| Coverage drops > 5% | #engineering | ğŸŸ¡ Medium |
| Flaky test detected | #engineering | ğŸŸ¡ Medium |
| Security vulnerability | #security | ğŸ”´ High |
| Integration test failure | #ops | ğŸŸ¡ Medium |

**Notification Format:**

```
ğŸ”´ Test Failure on main

Branch: main
Commit: abc1234
Author: @user
Failed Tests: 3

1. test_auth_validation (packages/api)
2. should create device (packages/schema)
3. integration_agent_connection (tests/integration)

View details: https://github.com/.../actions/runs/123

@channel Please investigate and fix ASAP.
```

**Slack Webhook Configuration:**

```yaml
# .github/workflows/notify.yml
- name: Notify on failure
  if: failure()
  uses: slackapi/slack-github-action@v1
  with:
    channel-id: 'C01234567'
    slack-message: |
      :red_circle: Test Failure on ${{ github.ref }}
      Commit: ${{ github.sha }}
      Author: ${{ github.actor }}
      View: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
  env:
    SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
```

### Email Notifications

**Recipients:**

- Engineering team: test failures, coverage drops
- Security team: vulnerability alerts
- Leadership: weekly/monthly summaries

**Email Templates:**

**Test Failure:**

```
Subject: [NGFW.sh] Test Failure on main - URGENT

Dear Engineering Team,

A test failure has been detected on the main branch.

Details:
- Commit: abc1234
- Author: John Doe
- Failed Tests: 3
- Time: 2026-02-09 14:32 UTC

Failed Tests:
1. test_auth_validation (packages/api)
2. should create device (packages/schema)
3. integration_agent_connection (tests/integration)

Action Required:
Please investigate and fix these failures as soon as possible.

View full report: https://github.com/.../actions/runs/123

Best regards,
NGFW.sh CI/CD System
```

**Weekly Summary:**

```
Subject: [NGFW.sh] Weekly Test Report - Week of Feb 9, 2026

Dear Engineering Team,

Here's your weekly test report for NGFW.sh:

ğŸ“Š Overview:
- Total Tests: 145 (+13 from last week)
- Pass Rate: 100% (+5.3%)
- Coverage: 75% (+2.1%)
- Flaky Tests: 0 (down from 3)

ğŸ¯ Achievements:
- âœ… All flaky tests resolved
- âœ… 100% pass rate achieved
- âœ… 13 new tests added

âš ï¸ Areas for Improvement:
- Schema API coverage: 0% (blocked by vitest v4)
- Portal tests: Not started
- Critical path coverage: 60% (target: 100%)

ğŸ“ˆ Trends:
[Coverage graph showing upward trend]

Next Week's Goals:
1. Resolve vitest v4 incompatibility
2. Start portal test development
3. Increase critical path coverage to 75%

Full report: https://reports.ngfw.sh/weekly/2026-02-09

Best regards,
NGFW.sh QA Team
```

### GitHub Notifications

**PR Comments:**

```markdown
## ğŸ“Š Test Report

âœ… All tests passed (145/145)
âœ… Coverage: 76.2% (+1.2%)
âœ… No security vulnerabilities

### Coverage by Package
- Schema API: N/A (blocked)
- Rust API: 75.3% (+2.1%)
- Agent: 92.0% (+0.5%)

### Test Execution Time
- Total: 23.45s
- Unit: 1.3s
- Integration: 28.1s

[View full report â†’](https://codecov.io/gh/danielbodnar/ngfw.sh/pull/123)
```

**Status Checks:**

```
âœ“ Lint â€” passed in 2m 34s
âœ“ Test Rust API â€” passed in 4m 12s
âš  Test Schema API â€” blocked (vitest v4)
âœ“ Integration Tests â€” passed in 3m 28s
âœ“ Build Verification â€” passed in 5m 16s
âœ“ Security Audit â€” passed in 2m 08s
```

---

## Reporting Automation

### Automated Report Generation

**Script:** `scripts/generate-test-report.ts`

```typescript
// scripts/generate-test-report.ts
import { readFileSync } from 'fs';
import { parse } from 'junit-parser';

interface TestReport {
  totalTests: number;
  passed: number;
  failed: number;
  skipped: number;
  coverage: number;
  executionTime: number;
}

async function generateReport(): Promise<TestReport> {
  // Parse JUnit XML reports
  const schemaXml = readFileSync('reports/ci/test-schema.xml', 'utf8');
  const rustXml = readFileSync('reports/ci/test-rust.xml', 'utf8');

  const schemaResults = parse(schemaXml);
  const rustResults = parse(rustXml);

  // Aggregate results
  const report: TestReport = {
    totalTests: schemaResults.tests + rustResults.tests,
    passed: schemaResults.passed + rustResults.passed,
    failed: schemaResults.failures + rustResults.failures,
    skipped: schemaResults.skipped + rustResults.skipped,
    coverage: calculateCoverage(),
    executionTime: schemaResults.time + rustResults.time,
  };

  return report;
}

function calculateCoverage(): number {
  // Read coverage reports
  const schemaCoverage = JSON.parse(
    readFileSync('packages/schema/coverage/coverage.json', 'utf8')
  );
  const rustCoverage = JSON.parse(
    readFileSync('packages/api/coverage/coverage.json', 'utf8')
  );

  // Calculate weighted average
  const totalLines = schemaCoverage.total.lines + rustCoverage.total.lines;
  const coveredLines = schemaCoverage.covered.lines + rustCoverage.covered.lines;

  return (coveredLines / totalLines) * 100;
}

// Generate and output report
generateReport().then(report => {
  console.log(JSON.stringify(report, null, 2));

  // Send to monitoring system
  sendToInfluxDB(report);

  // Generate email
  sendEmailReport(report);
});
```

**Run automatically:**

```yaml
# .github/workflows/test.yml
- name: Generate test report
  if: always()
  run: bun run scripts/generate-test-report.ts

- name: Upload report
  uses: actions/upload-artifact@v4
  with:
    name: test-report
    path: reports/test-report.json
```

### Report Distribution

**Cron Job:**

```bash
# crontab
0 9 * * 1 /usr/local/bin/generate-weekly-report.sh  # Every Monday at 9 AM
0 9 1 * * /usr/local/bin/generate-monthly-report.sh # First day of month at 9 AM
```

**generate-weekly-report.sh:**

```bash
#!/usr/bin/env bash

set -euo pipefail

# Generate report
cd /path/to/ngfw.sh
bun run scripts/generate-weekly-report.ts

# Convert to PDF
pandoc reports/summaries/weekly/$(date +%Y-%m-%d).md \
  -o reports/summaries/weekly/$(date +%Y-%m-%d).pdf

# Send via email
cat reports/summaries/weekly/$(date +%Y-%m-%d).md | \
  mail -s "[NGFW.sh] Weekly Test Report" \
    -a reports/summaries/weekly/$(date +%Y-%m-%d).pdf \
    engineering@ngfw.sh

# Upload to S3
aws s3 cp reports/summaries/weekly/$(date +%Y-%m-%d).pdf \
  s3://ngfw-reports/weekly/
```

---

## Custom Reporting Tools

### Test Dashboard CLI

```bash
# Install
bun install -g @ngfw/test-dashboard

# View current status
ngfw-test status

# View coverage
ngfw-test coverage --package schema

# View trends
ngfw-test trends --days 30

# Generate report
ngfw-test report --type weekly --output pdf
```

### Web Dashboard

**Stack:** Next.js + Tailwind CSS

**URL:** https://dashboard.ngfw.sh/tests

**Features:**
- Real-time test status
- Coverage visualizations
- Trend charts
- Failed test details
- Historical data

**Implementation:**

```typescript
// app/tests/page.tsx
export default async function TestsPage() {
  const testResults = await fetchTestResults();
  const coverage = await fetchCoverage();

  return (
    <div>
      <h1>Test Dashboard</h1>
      <TestStatusCard results={testResults} />
      <CoverageChart coverage={coverage} />
      <FailedTestsList failures={testResults.failures} />
      <TrendChart data={testResults.history} />
    </div>
  );
}
```

---

*Last updated: 2026-02-09*
